name: CI

on:
  pull_request:
    types:
      - opened
      - labeled
      - synchronize
  pull_request_review:
    types:
      - submitted
      - edited

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number }}
  cancel-in-progress: ${{ github.event.action == 'synchronize' }}

jobs:
  triggers:
    name: Get Triggers
    runs-on: ubuntu-latest
    outputs:
      is_pull_request_opened: ${{ github.event_name == 'pull_request' && github.event.action == 'opened'}}
      is_pull_request_review_approved: ${{ github.event_name == 'pull_request_review' && github.event.review.state == 'APPROVED'}}
      is_pull_request_labeled_with_run_tests: ${{ github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'run-tests')}}
    steps:
      - run: true

  test:
    needs: triggers
    if: ${{ needs.triggers.outputs.is_pull_request_opened == 'true' || needs.triggers.outputs.is_pull_request_review_approved == 'true' || needs.triggers.outputs.is_pull_request_labeled_with_run_tests == 'true' }}

    runs-on: ubuntu-latest

    env:
      PYTHONPATH: ${{ github.workspace }}
      COMPOSE_PROFILES: hardhat

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Copy .env file
        run: cp .env.example .env

      # TODO: we should also add also heuristai and anthropic keys to the e2e tests and test all providers

      - name: Set OPENAIKEY in the .env file so it can be loaded from the environment
        env:
          OPENAIKEY: ${{ secrets.OPENAIKEY }}
        run: |
          sed -i "s/<add_your_openai_api_key_here>/${OPENAIKEY}/g" .env
          sed -i "s/VITE_FINALITY_WINDOW=\".*\"/VITE_FINALITY_WINDOW=\"10\"/" .env
          sed -i "s/COMPOSE_RPC_CPU_LIMIT=\".*\"/COMPOSE_RPC_CPU_LIMIT=\"4\"/" .env
          sed -i "s/COMPOSE_WORKER_CPU_LIMIT=\".*\"/COMPOSE_WORKER_CPU_LIMIT=\"4\"/" .env
          sed -i "s/COMPOSE_RPC_MEM_RESERVATION=\".*\"/COMPOSE_RPC_MEM_RESERVATION=\"1\"/" .env
          sed -i "s/COMPOSE_WORKER_MEM_RESERVATION=\".*\"/COMPOSE_WORKER_MEM_RESERVATION=\"1\"/" .env
          sed -i "s/COMPOSE_RPC_MEM_LIMIT=\".*\"/COMPOSE_RPC_MEM_LIMIT=\"6gb\"/" .env
          sed -i "s/COMPOSE_WORKER_MEM_LIMIT=\".*\"/COMPOSE_WORKER_MEM_LIMIT=\"6gb\"/" .env
          sed -i "s/COMPOSE_RPC_MEM_RESERVATION=\".*\"/COMPOSE_RPC_MEM_RESERVATION=\"2gb\"/" .env
          sed -i "s/COMPOSE_WORKER_MEM_RESERVATION=\".*\"/COMPOSE_WORKER_MEM_RESERVATION=\"2gb\"/" .env
          sed -i "s/JSONRPC_REPLICAS=\".*\"/JSONRPC_REPLICAS=\"1\"/" .env
          sed -i "s/CONSENSUS_WORKERS=\".*\"/CONSENSUS_WORKERS=\"3\"/" .env
          sed -i "s/MAX_PARALLEL_TXS_PER_WORKER=\".*\"/MAX_PARALLEL_TXS_PER_WORKER=\"2\"/" .env
          echo >> .env
          if [[ "${{ needs.triggers.outputs.is_pull_request_review_approved }}" == "true" ]]; then
            echo "TEST_WITH_MOCK_LLMS=false" >> .env
          else
            echo "TEST_WITH_MOCK_LLMS=true" >> .env
          fi

      # Set up Python + pip early so it overlaps with Docker build
      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.14"
          cache: pip
          cache-dependency-path: |
            requirements.txt
            requirements.test.txt
            backend/requirements.txt

      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements.test.txt
          pip install -r backend/requirements.txt

      - name: Extract GenVM version for cache key
        id: genvm
        run: echo "tag=$(grep -m1 'ARG GENVM_TAG=' docker/Dockerfile.backend | cut -d= -f2)" >> "$GITHUB_OUTPUT"

      - name: Restore GenVM precompile cache
        uses: actions/cache@v5
        with:
          path: /tmp/genvm-cache
          key: genvm-precompile-${{ steps.genvm.outputs.tag }}-amd64

      - name: Prepare GenVM cache directory
        run: mkdir -p /tmp/genvm-cache/pc && chmod -R 0777 /tmp/genvm-cache

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Build only backend images with Buildx Bake and enable GHA cache
      - name: Build backend images with cache (buildx bake)
        uses: docker/bake-action@v6
        with:
          files: |
            ./docker-compose.yml
          targets: |
            database-migration
            jsonrpc
            consensus-worker
          set: |
            *.cache-from=type=gha
            *.cache-to=type=gha,mode=max
            database-migration.tags=genlayer-studio-database-migration:latest
            jsonrpc.tags=genlayer-studio-jsonrpc:latest
            consensus-worker.tags=genlayer-studio-consensus-worker:latest
          load: true

      # Start services without rebuilding images; CI override mounts GenVM precompile cache
      - name: Run Docker Compose
        run: docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d --no-build database-migration jsonrpc consensus-worker

      - name: Wait for services to be up
        timeout-minutes: 5
        run: |
          timeout=60
          counter=0
          while [[ "$counter" -lt "$timeout" ]]; do
            if curl -sS -X POST -H "Content-Type: application/json" -d '{"jsonrpc":"2.0","method":"ping","params":[],"id":1}' http://0.0.0.0:4000/api 2>/dev/null | grep -q "OK"; then
              echo "RPC server is up!"
              break
            else
              echo "Waiting for RPC server... ($counter/$timeout)"
              sleep 2
              counter=$((counter+1))
            fi
          done
          if [[ "$counter" -ge "$timeout" ]]; then
            echo "Error: Timeout while waiting for RPC server"
            exit 1
          fi

      - name: Run tests (parallel)
        run: gltest --contracts-dir . --default-wait-retries 140 tests/integration/ -svv -n 8 --ignore=tests/integration/test_validators.py

      # Validator smoke test runs serial (GenVM LLM module restarts on each CRUD op).
      # Full CRUD coverage is in db-sqlalchemy/validators_registry_test.py (<1s).
      - name: Run validator smoke test (serial)
        run: gltest --contracts-dir . --default-wait-retries 140 tests/integration/test_validators.py -svv

      - name: Dump Docker Compose logs
        run: docker compose logs
        if: failure()

      - name: Shutdown Docker Compose
        if: always()
        run: docker compose down

  db-integration-test:
    needs: triggers
    if: ${{ needs.triggers.outputs.is_pull_request_opened == 'true' || needs.triggers.outputs.is_pull_request_review_approved == 'true' || needs.triggers.outputs.is_pull_request_labeled_with_run_tests == 'true' }}

    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v5
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Run Docker Compose
        run: docker compose -f tests/db-sqlalchemy/docker-compose.yml --project-directory . run --build --rm tests


  # hardhat-test:
  #   needs: triggers
  #   if: ${{ needs.triggers.outputs.is_pull_request_opened == 'true' || needs.triggers.outputs.is_pull_request_review_approved == 'true' || needs.triggers.outputs.is_pull_request_labeled_with_run_tests == 'true' }}

  #   runs-on: ubuntu-latest

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4

  #     - name: Set up Docker Buildx
  #       uses: docker/setup-buildx-action@v3

  #     - name: Cache Docker layers
  #       uses: actions/cache@v4
  #       with:
  #         path: /tmp/.buildx-cache
  #         key: ${{ runner.os }}-buildx-${{ github.sha }}
  #         restore-keys: |
  #           ${{ runner.os }}-buildx-

  #     - name: Run Docker Compose
  #       run: docker compose -f tests/hardhat/docker-compose.yml --project-directory . up tests --build --force-recreate --always-recreate-deps


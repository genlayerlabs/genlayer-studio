# Postgres Database Configuration
DBHOST="postgres"
DBNAME="genlayer_state"
DBUSER="postgres"
DBPASSWORD="postgres"
DBPORT="5432"
POSTGRES_HOST="${DBHOST}"
POSTGRES_DB="${DBNAME}"
POSTGRES_USER="${DBUSER}"
POSTGRES_PASSWORD="${DBPASSWORD}"
POSTGRES_PORT="${DBPORT}"
DEFAULT_VALIDATORS_COUNT="5"

# Logging Configuration
LOGCONFIG="dev"  # dev/prod
LOG_LEVEL="info"  # debug/info/warning/error/critical
FLASK_LOG_LEVEL="ERROR"  # legacy; ignored by FastAPI
DISABLE_INFO_LOGS_ENDPOINTS="[\"ping\", \"eth_getTransactionByHash\",\"gen_getContractSchemaForCode\",\"gen_getContractSchema\"]"

# JsonRPC Server Configuration
RPCPROTOCOL="http"
RPCHOST="jsonrpc"
RPCPORT="4000"
RPCDEBUGPORT="4678"
JSONRPC_REPLICAS="1"
ENABLE_DEBUG_ENDPOINTS="false"

# GenVM Configuration
GENVM_BIN="/genvm/bin"

# VSCode Debug Configuration
VSCODEDEBUG="false"

# Ollama Server Configuration
OLAMAPROTOCOL="http"
OLAMAHOST="ollama"
OLAMAPORT="11434"

# WebRequest Server Configuration
WEBDRIVERHOST="webdriver"
WEBDRIVERPORT="5001"

# NGINX Server Configuration
SERVER_NAME="studio.genlayer.com"

# Frontend Configuration
# If you want to run the frontend in production, change http to https and ws to wss
VITE_JSON_RPC_SERVER_URL="http://127.0.0.1:4000/api"  # if VITE_PROXY_ENABLED = 'true' change to '/api'
VITE_WS_SERVER_URL="ws://127.0.0.1:4000"  # if VITE_PROXY_ENABLED = 'true' change to '/'
VITE_PLAUSIBLE_DOMAIN="studio.genlayer.com"
FRONTEND_PORT="8080"
FRONTEND_BUILD_TARGET="final"  # change to 'dev' to run in dev mode

# Vite Proxy Configuration (for local development)
VITE_PROXY_ENABLED="false"
VITE_PROXY_JSON_RPC_SERVER_URL="http://jsonrpc:4000"
VITE_PROXY_WS_SERVER_URL="ws://jsonrpc:4000"
VITE_IS_HOSTED="false"

# Backend Configuration
BACKEND_BUILD_TARGET="debug"  # change to 'prod' or remove to run in prod mode

# Production Configuration
FLASK_DEBUG="0"  # '0' or '1' (never use '1' in production)
FLASK_ENV="production"  # 'development' or 'production'
WEB_CONCURRENCY="1"  # Number of worker processes
DATABASE_POOL_SIZE="20"  # Database connection pool size
DATABASE_MAX_OVERFLOW="10"  # Maximum overflow connections
REDIS_URL="redis://redis:6379/0"  # Redis URL for WebSocket broadcast
REDIS_PORT="6379"
STATSD_HOST=""
ALLOW_UNSAFE_WERKZEUG="false"  # Only set to 'true' for development

# Hardhat port
HARDHAT_URL="http://hardhat"
HARDHAT_PORT="8545"
HARDHAT_PRIVATE_KEY="0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80"

# Consensus Parameters
CONSENSUS_CONTRACT_ADDRESS="0x0000000000000000000000000000000000000000"
DEFAULT_NUM_INITIAL_VALIDATORS="5"
DEFAULT_CONSENSUS_MAX_ROTATIONS="3"

# LLM Providers Configuration
# If you want to use OpenAI LLMs, add your key here
OPENAIKEY="<add_your_openai_api_key_here>"

# If you want to use Anthropic AI LLMs, add your key here
ANTHROPIC_API_KEY="<add_your_anthropic_api_key_here>"

# If you want to use Google AI LLMs, add your key here
GEMINI_API_KEY="<add_your_gemini_api_key_here>"

# If you want to use XAI LLMs, add your key here
XAI_API_KEY="<add_your_xai_api_key_here>"

# If you want to use Heurist AI LLMs, add your key here
HEURISTAIURL="https://llm-gateway.heurist.xyz"
HEURISTAIMODELSURL="https://raw.githubusercontent.com/heurist-network/heurist-models/main/models.json"
HEURISTAIAPIKEY="<add_your_heuristai_api_key_here>"

# Validator Configuration
# JSON array of initial validators to be created on startup.
# Example:
# VALIDATORS_CONFIG_JSON='[
#   {"stake": 100, "provider": "openai", "model": "gpt-4o", "amount": 2},
#   {"stake": 100, "provider": "openai", "model": "gpt-4-1106-preview", "amount": 2},
#   {"stake": 100, "provider": "xai", "model": "grok-2-1212", "amount": 2},
#   {"stake": 100, "provider": "anthropic", "model": "claude-3-5-haiku-20241022", "amount": 2},
#   {"stake": 100, "provider": "anthropic", "model": "claude-3-7-sonnet-20250219", "amount": 2},
#   {"stake": 100, "provider": "heuristai", "model": "mistralai/mixtral-8x7b-instruct", "amount": 1},
#   {"stake": 100, "provider": "heuristai", "model": "meta-llama/llama-3.3-70b-instruct", "amount": 1},
#   {"stake": 100, "provider": "heuristai", "model": "deepseek/deepseek-v3", "amount": 1},
#   {"stake": 100, "provider": "google", "model": "gemini-2.0-flash-lite-001", "amount": 2}
# ]'
VALIDATORS_CONFIG_JSON=""

# Consensus mechanism
VITE_FINALITY_WINDOW="1800"  # in seconds
VITE_FINALITY_WINDOW_APPEAL_FAILED_REDUCTION="0.2"  # 20% reduction per appeal failed
VITE_MAX_ROTATIONS="3"

# Set the compose profile to 'hardhat' to use the hardhat network
COMPOSE_PROFILES="hardhat"
REMOTE_DATABASE="false"
COMPOSE_CPU_LIMIT="12"
COMPOSE_CPU_RESERVATION="2"
COMPOSE_MEM_LIMIT="42gb"
COMPOSE_MEM_RESERVATION="8gb"

# Hardhat chain ID
HARDHAT_CHAIN_ID="61999"

# Load test parameters
REQUESTS="10"
CONCURRENCY="5"

# Validator configuration for sim_createValidator
VALIDATOR_STAKE="1"
VALIDATOR_PROVIDER="openai"
VALIDATOR_MODEL="gpt-4-1106-preview"
VALIDATOR_PLUGIN="openai-compatible"

# Funding parameters
FUND_AMOUNT="100"

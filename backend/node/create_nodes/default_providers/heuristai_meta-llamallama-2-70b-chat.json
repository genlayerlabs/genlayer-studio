{
  "provider": "heuristai",
  "plugin": "heuristai",
  "model": "meta-llama/llama-2-70b-chat",
  "config": {
    "temperature": 0.75,
    "max_tokens": 500
  }
}

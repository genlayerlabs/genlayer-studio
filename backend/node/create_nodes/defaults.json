[
  {
    "providers": {
      "provider_weights": {
        "ollama": 0.5,
        "openai": 0.5,
        "heuristai": 0.5
      },
      "openai_models": "gpt-4,gpt-4o,gpt-4o-mini",
      "heuristai_models": "mistralai/mixtral-8x7b-instruct,meta-llama/llama-2-70b-chat,openhermes-2-yi-34b-gptq,dolphin-2.9-llama3-8b",
      "chance_of_default_value": 0.5
    },
    "node_defaults": [
      {
        "provider": "ollama",
        "options": {
          "mirostat": { "default": 0, "min": 0, "max": 2, "step": 1 },
          "mirostat_eta": { "default": 0.1, "min": 0, "max": 1, "step": 0.01 },
          "mirostat_tau": { "default": 5, "min": 0, "max": 10, "step": 0.1 },
          "num_ctx": {
            "default": 2048,
            "min": 512,
            "max": 4096,
            "step": "512,1024,2048,4096",
            "comment": "this needs to be a per model value"
          },
          "num_gqa": { "default": 8, "min": 1, "max": 20, "step": 1 },
          "num_gpu": { "default": 0, "min": 0, "max": 16, "step": 1 },
          "num_thread": { "default": 2, "min": 1, "max": 16, "step": 1 },
          "repeat_last_n": {
            "default": 64,
            "min": 8,
            "max": 4096,
            "step": "8,16,32,64,128,256,512,1024,2048,4096"
          },
          "repeat_penalty": {
            "default": 1.1,
            "min": 1.0,
            "max": 2.0,
            "step": 0.1
          },
          "temprature": { "default": 0.8, "min": 0.0, "max": 1.5, "step": 0.1 },
          "seed": { "default": 0, "min": 0, "max": 1000000, "step": 1 },
          "stop": "",
          "tfs_z": { "default": 1.0, "min": 1.0, "max": 2.0, "step": 0.1 },
          "num_predict": {
            "default": 128,
            "min": -2,
            "max": 512,
            "step": "-2,-1,32,64,128,256,512"
          },
          "top_k": { "default": 40, "min": 2, "max": 100, "step": 1 },
          "top_p": { "default": 0.9, "min": 0.5, "max": 0.99, "step": 0.01 }
        }
      },
      {
        "provider": "heuristai",
        "options": {
          "temperature": {
            "default": 0.75,
            "min": 0.0,
            "max": 1.0,
            "step": 0.05
          },
          "max_tokens": { "default": 500, "min": 100, "max": 2000, "step": 10 }
        }
      },
      {
        "provider": "openai",
        "options": "<empty>"
      }
    ],
    "node_custom": [
      {
        "provider": "ollama",
        "config": [
          {
            "model": "llama3",
            "options": {
              "num_ctx": 2048
            }
          },
          {
            "model": "mistral",
            "options": {
              "mirostat": 0,
              "mirostat_eta": 0.2,
              "num_ctx": 2048,
              "temprature": 0.7,
              "num_predict": 64
            }
          },
          {
            "model": "gemma",
            "options": {
              "num_ctx": 2048,
              "temprature": 0.9
            }
          }
        ]
      }
    ]
  }
]
